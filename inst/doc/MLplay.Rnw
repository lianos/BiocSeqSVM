%\VignetteIndexEntry{Maching learning from NGS data}
%\VignetteKeywords{tutorial}
%\VignettePackage{MLplay}
\documentclass[11pt]{article}

\usepackage{url}
\usepackage{colortbl}
\usepackage{amsmath}
\usepackage[pdftex]{graphicx}
\usepackage{color}
\usepackage{xspace}
\usepackage{fancyvrb}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{booktabs} 
\usepackage{longtable} 
\usepackage[boxed, linesnumbered]{algorithm2e}
\usepackage[
         colorlinks=true,
         linkcolor=blue,
         citecolor=blue,
         urlcolor=blue]
         {hyperref}
\usepackage{lscape}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Try to make things look purty
%% I like to use the fullpage!
\usepackage{fullpage}

%% Do not indent paragraphs
\usepackage[parfill]{parskip}

%% And fonts!
% For bold and small caps together
% http://stackoverflow.com/questions/699371/latex-small-caps-and-bold-face
\usepackage[T1]{fontenc}

%% Use Helvetica
\usepackage{times}
\usepackage[scaled=1]{helvet}     % PostScript font Helvetica for sans serif
\renewcommand{\rmdefault}{phv}    % Helvetica for roman type as well as sf
\renewcommand{\sfdefault}{phv}    % Helvetica for roman type as well as sf

% Inconsolata for monospaced fonts
% (fortunately this is distributed with the TeX-live distribution)
\usepackage{inconsolata}

%% End: Purty -----------------------------------------------------------------

\usepackage{Sweave}
\SweaveOpts{keep.source=TRUE}

% define new colors for use
\definecolor{darkgreen}{rgb}{0,0.6,0}
\definecolor{darkred}{rgb}{0.6,0.0,0}
\definecolor{lightbrown}{rgb}{1,0.9,0.8}
\definecolor{brown}{rgb}{0.6,0.3,0.3}
\definecolor{darkblue}{rgb}{0,0,0.8}
\definecolor{darkmagenta}{rgb}{0.5,0,0.5}

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textit{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}
\newcommand{\Rcode}[1]{{\texttt{#1}}}
\newcommand{\software}[1]{\textsf{#1}}
\newcommand{\R}{\software{R}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{fancy}

%% Either
% \lhead{}
% \chead{Machine Learning and NGS data}
% \rhead{}
% \lfoot{}
% \cfoot{}
% \rfoot{\thepage\ of \pageref{LastPage}}
% \renewcommand{\headrulewidth}{1pt}
% \renewcommand{\footrulewidth}{1pt}

%% Or
\fancyhead[RO,RE]{\slshape \leftmark}
% Using fancy headers sometimes lets figures, etc. bleed into the header, this
% trick has fixed it for me in the past
\setlength\headsep{25pt}

\title{Exploring the preferred binding landscape of an RNA binding protein using high throughput sequencing data and machine learning}

\author{
  Steve Lianoglou \\
  Memorial Sloan-Kettering Cancer Center \\
  \small{\texttt{lianos@cbio.mskcc.org}}
}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Title page

\maketitle

The goal of this tutorial is to explore how some machine learning techniques,
particularly support vector machines and string kernels, can be used
with next generation sequencing data in order to have fun with biology. We will
be using different types of sequencing data (RNA-seq and HITS-CLIP) in order to
model the ``preferred binding landscape'' of an RNA binding protein
(pasilla/NOVA) and see if this landscape is conserved among evolutionary
distant eukaryotes (fruit fly and mouse).

\renewcommand{\baselinestretch}{.6}

\tableofcontents

\thispagestyle{empty}
	
\vspace{.2in}

\renewcommand{\baselinestretch}{1}

<<loadLibs, results = hide, echo = FALSE>>=
#library(GenomicRanges)
#library(caret)
#library(sg)
#library(pasilla)
#library(BSgenome.Dmelanogaster.UCSC.dm3)
#library(BSgenome.Mmusculus.UCSC.mm9)
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Motivation
\section{Motivation}
\label{sec:motivation}
The RNA binding protein (RBP) known as \emph{NOVA-1} (and \emph{NOVA-2}) in higher eukaryotes, and pasilla (ps) in fly, has been previously implicated in playing a role in the regulation of alternative splicing.


%% ============================================================================
%% Caveat emptor
\subsection{Caveat emptor}
\label{sub:caveat_emptor}
This tutorial is not meant to serve as a general purpose introduction to
machine learning concepts. Other tutorials are available that you can find online
that can serve this purpose. In particular, the ML lab and slides prepared by
Vincent Carey for the
\href{http://www.bioconductor.org/help/course-materials/2011/CSAMA/}{CSAMA 2011 workshop}
are worth exploring.

We will be taking a deep dive into exploring how we can combine the types of high-resolution
data that different sequencing approaches provide with support vector machines (SVMs) to dig
around in the biology outlined in the motivation section above. Our goal is not to build a
100\% perfectly accurate classifier (although that would be nice!). We are more interested in
understanding something a bit more about biology using our machine learning models. We will
partially be relying on the functionality found in the Shogun machine learning toolbox, which is a
library written in \texttt{C++} with binding to several languages~\cite{Sonnenburg:2010tr}. The
downside to using Shogun from \texttt{R} is that it is not installable from \texttt{CRAN} and you
will find that its language bindings are highly un-idiomatic \texttt{R} style.
% subsection caveat_emptor

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Support vector machines
\section{Support Vector Machines}
\label{sec:support_vector_machines}

Support vector machines (SVMs) (cite vapnik) ...

%% ============================================================================
%% String Kernels
\subsection{String Kernels} % (fold)
\label{sub:string_kernels}

There are different ways to measure distance/similarity between strings.

%% ----------------------------------------------------------------------------
%% Spectrum Kernel
\subsubsection{Spectrum Kernel} % (fold)
\label{ssub:spectrum_kernel}
Cite Christina

\begin{equation}
  k(x,x') = \sum_{u \in \Sigma^d} N(u, x) N(u, x')
\end{equation}

where $N(u,x)$ is the function that returns the number of occurrences of kmer $u$ in the string $x$.

%% ----------------------------------------------------------------------------
%% Weighted Degree Kernel
\subsubsection{Weighted Degree Kernel}
\label{ssub:weighted_degree_kernel}

The \emph{weighted degree} (WD) kernel computes similarities between
sequences while taking positional information into account. The WD kernel
counts the exact co-occurrences of \emph{k}-mers at corresponding positions
of the two sequences being compared.

\begin{figure}[htbp]
  \centering
    \includegraphics[scale=1]{figs/weighted-degree-kernel}
  \caption{
    Given two sequences $x_1$ and $x_2$ of equal length, the kernel
    computes a weighted sum of matching subsequences. Each matching
    subsequence makes a contribution $w_B$ depending on its length $B$,
    where longer matches contribute more significantly.}
  \label{fig:WDK}
\end{figure}

\begin{equation}
  k(x,x') = \sum_{k=1}^d \beta_k \sum_{i=1}^{l-k+1} \hbox{I}(u_{k,i}(x) = u_{k,i}(x'))
\end{equation}


%% ----------------------------------------------------------------------------
%% Weighted Degree Kernel with Shifts
\subsubsection{Weighted Degree Kernel with Shifts}
\label{ssub:weighted_degree_kernel_with_shifts}

The weighted degree kernel with shifts (the WDS kernel) shifts the two
sequences against each other in order to allow for small positional variations
of sequence motifs. It is conceptually a combination of the spectrum and WD
kernels.

\begin{figure}[htbp]
  \centering
    \includegraphics[scale=1]{figs/weighted-degree-kernel-with-shifts}
  \caption{
    Given two sequences $x_1$ and $x_2$ of equal length, the WDS kernel produces
    a weighted sum to which each match in the sequences makes a contribution
    $\gamma_{k,p}$ depending on its length $k$ and relative position $p$, where
    longer matches at the same position contribute more significantly.
  }
  \label{fig:WDKS}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Learning preferred binding landscapes
\section{Learning preferred binding landscapes}
\label{sec:learning_preferred_binding_landscapes}


%% ============================================================================
%% Feature selection
\subsection{Feature selection}
\label{sub:feature_selection}


%% ============================================================================
%% Training
\subsection{Training}
\label{sub:training}



%% ============================================================================
%% Testing
\subsection{Testing}
\label{sub:testing}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Applying model on novel organism
\section{Applying model on novel organism}
\label{sec:applying_model_on_novel_organism}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Unsupervised learning with NFM
\section{Unsupervised learning with Nonnegative Matrix Factorization}
\label{sec:unsupervised_learning_with_nonnegative_matrix_factorization}
Non-negative matrix factorization


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Future things to explore
\section{Future things to explore}
\label{sec:future}
Novel Machine Learning Methods for MHC Class I Binding Prediction
http://www.fml.tuebingen.mpg.de/raetsch/members/raetsch/bibliography/WTAKR2010
http://www.fml.tuebingen.mpg.de/raetsch/lectures/talk-multitask-recomb2010.pdf


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements
\section{Acknowledgements}
\label{sec:acknowledgements}
Christina Leslie, Raphael Pelessof, Gunnar Raetsch, Chris Widmer


\bibliography{MLplay}
\bibliographystyle{plain}


\section{Session Information}
<<sessionInfo>>=
sessionInfo()
@ 

\end{document}